{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b354703-08f0-48be-bdb6-c3ca7424bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf97c86-cd63-4a4d-8aaa-f5e608e43c39",
   "metadata": {},
   "source": [
    "# 1 carregando dados prontos dos candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2481d1-b38e-4fd8-abf8-4b7eeca39cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = pd.read_csv('C:/excel/Candidatos/canditatosfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ee55f-a05e-4c85-bbf7-877902784d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e72225-1186-4a79-bc2d-6c0141456cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c596b-58e0-46e7-bc28-2858d25ecaf2",
   "metadata": {},
   "source": [
    "# 2 Separando os arquivos teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8c95d-35c9-4b3a-90ab-6e95d5f04a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = arquivo['aprovado_vaga']\n",
    "x = arquivo.drop('aprovado_vaga', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab1bdf-def4-443e-80ed-98f73afbd308",
   "metadata": {},
   "source": [
    "# 3 Criando os conjuntos de dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ffec3-c3cd-4485-b1fe-239d2ecd70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf23d51-c943-4533-9571-a1531bdec2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Analizando o melhor modelo de calssificação \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos a serem testados (sem XGBoost e LightGBM)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Pré-processamento\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "x = imputer.fit_transform(x)\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "# Dividir os dados (usando minúsculas)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, \n",
    "                                                   random_state=42, \n",
    "                                                   stratify=y)\n",
    "\n",
    "# Lista de modelos para testar\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(class_weight='balanced', max_iter=1000)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier(class_weight='balanced')),\n",
    "    ('Random Forest', RandomForestClassifier(class_weight='balanced', random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "    ('SVM', SVC(class_weight='balanced', probability=True, random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),\n",
    "    ('LDA', LinearDiscriminantAnalysis()),\n",
    "    ('QDA', QuadraticDiscriminantAnalysis())\n",
    "]\n",
    "\n",
    "# Avaliar cada modelo\n",
    "results = []\n",
    "for name, model in models:\n",
    "    try:\n",
    "        # Criar pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Cross-validation com F1-Score\n",
    "        cv_scores = cross_val_score(pipeline, x_train, y_train, \n",
    "                                   cv=5, scoring=make_scorer(f1_score))\n",
    "        \n",
    "        # Treinar no conjunto completo\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        # Previsões no teste\n",
    "        y_pred = pipeline.predict(x_test)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Relatório de classificação detalhado\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'CV Mean F1': np.mean(cv_scores),\n",
    "            'CV Std F1': np.std(cv_scores),\n",
    "            'Test F1': test_f1,\n",
    "            'Test Precision': report['1']['precision'],\n",
    "            'Test Recall': report['1']['recall']\n",
    "        })\n",
    "        \n",
    "        print(f\"{name} - Test F1: {test_f1:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro no modelo {name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Converter resultados para DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResultados completos dos modelos (Ordenados por Test F1):\")\n",
    "print(results_df.sort_values('Test F1', ascending=False).to_string(index=False))\n",
    "\n",
    "# Adicional: Feature Importance do melhor modelo\n",
    "if not results_df.empty:\n",
    "    best_model_info = [(i, name, model) for i, (name, model) in enumerate(models) \n",
    "                      if name in results_df['Model'].values]\n",
    "    best_model_name = results_df.loc[results_df['Test F1'].idxmax(), 'Model']\n",
    "    \n",
    "    # Encontrar o modelo correspondente\n",
    "    best_model = None\n",
    "    for idx, name, model in best_model_info:\n",
    "        if name == best_model_name:\n",
    "            best_model = model\n",
    "            break\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(f\"\\nFeature Importance do melhor modelo ({best_model_name}):\")\n",
    "        \n",
    "        best_model.fit(x_train, y_train)\n",
    "        \n",
    "        if hasattr(best_model, 'feature_importances_'):\n",
    "            importances = best_model.feature_importances_\n",
    "            feature_importance = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "            print(feature_importance.sort_values('Importance', ascending=False))\n",
    "        elif hasattr(best_model, 'coef_'):\n",
    "            coefs = best_model.coef_[0] if len(best_model.coef_.shape) > 1 else best_model.coef_\n",
    "            feature_importance = pd.DataFrame({'Feature': features, 'Coefficient': coefs})\n",
    "            print(feature_importance.sort_values('Coefficient', ascending=False))\n",
    "        else:\n",
    "            print(\"Este modelo não fornece feature importance direta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4af0e-ec1a-43a5-be5e-a72a666cce2d",
   "metadata": {},
   "source": [
    "# 5 analizando os melhores parametros no modelo de Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5642eef-484a-42d5-9b75-3256e9cfef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir os parâmetros a serem testados\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 200, 500],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Criar o modelo\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Configurar o Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, \n",
    "                          param_grid=param_grid, \n",
    "                          cv=5, \n",
    "                          scoring='accuracy',\n",
    "                          n_jobs=-1)\n",
    "\n",
    "# Executar o Grid Search\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "print(\"Melhor score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8cca4-3710-4801-99c3-effcfaf5b00e",
   "metadata": {},
   "source": [
    "# 6 criando o modelo com os melhores parametros para o modelo de logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253da3c-31f8-4c67-9c3d-4dea72f13111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Criar o modelo com os melhores parâmetros encontrados\n",
    "best_params = {\n",
    "    'C': 0.001,\n",
    "    'class_weight': None,\n",
    "    'max_iter': 100,\n",
    "    'penalty': 'l1',\n",
    "    'solver': 'liblinear'\n",
    "}\n",
    "\n",
    "# Instanciar o modelo\n",
    "log_reg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    class_weight=best_params['class_weight'],\n",
    "    max_iter=best_params['max_iter'],\n",
    "    penalty=best_params['penalty'],\n",
    "    solver=best_params['solver'],\n",
    "    random_state=42  # para reprodutibilidade\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "log_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea761d-78f0-4c5a-bffb-7060a4bfde14",
   "metadata": {},
   "source": [
    "# 7 testando o modelo e visualizando a acuracia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac60e42-4ae7-4949-b702-f8cf1aeb888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "y_pred = log_reg.predict(x_test)\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907701c-93aa-42f5-bed7-26c31c4cf4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
